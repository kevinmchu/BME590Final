{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import sqlite3 # library for working with sqlite database\n",
    "conn = sqlite3.connect(\"./data/data.db\") # Create a connection to the on-disk database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM sqlite_master where type='table'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_sql(\"\"\"SELECT * FROM admissions LIMIT 10\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_df = pd.read_sql(\"SELECT * FROM patients\", conn)\n",
    "adm_df = pd.read_sql(\"SELECT * FROM admissions\", conn)\n",
    "pat_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_admissions = pd.read_sql(\"\"\"SELECT * FROM admissions\"\"\", conn)\n",
    "print(all_admissions.shape)\n",
    "all_admissions = all_admissions.sort_values('SUBJECT_ID')\n",
    "all_admissions_info = all_admissions[['SUBJECT_ID', 'HADM_ID', 'HOSPITAL_EXPIRE_FLAG']]\n",
    "all_admissions_info[5:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Â 'First' admission if it is a patient's first ever admission\n",
    "# Exclude patients who die during their 'first' visit\n",
    "\n",
    "one_admission = pd.read_sql(\"\"\"SELECT SUBJECT_ID, HOSPITAL_EXPIRE_FLAG FROM admissions\n",
    "GROUP BY SUBJECT_ID\n",
    "HAVING COUNT(SUBJECT_ID) = 1\n",
    "\"\"\", conn)\n",
    "print(\"Number of people admitted once: \" + str(one_admission.shape[0]))\n",
    "one_admission_deaths = one_admission.iloc[one_admission['HOSPITAL_EXPIRE_FLAG'].values == 1]\n",
    "one_admission_deaths = one_admission_deaths[['SUBJECT_ID']]\n",
    "print(\"People who died on their first admission:\")\n",
    "print(one_admission_deaths.shape[0])\n",
    "print(one_admission_deaths.head())\n",
    "\n",
    "one_admission_survivors = one_admission[one_admission['HOSPITAL_EXPIRE_FLAG'] == 0]\n",
    "one_admission_survivors = one_admission_survivors[['SUBJECT_ID']]\n",
    "print(\"People who only had one admission but survived it: \" + str(one_admission_survivors.shape[0]))\n",
    "print(one_admission_survivors[0:15])\n",
    "\n",
    "mult_admissions = pd.read_sql(\"\"\"SELECT SUBJECT_ID FROM admissions\n",
    "GROUP BY SUBJECT_ID\n",
    "HAVING COUNT(SUBJECT_ID) > 1\n",
    "ORDER BY CAST(SUBJECT_ID AS UNSIGNED) ASC\n",
    "\"\"\", conn)\n",
    "print(\"People who had multiple admissions: \" + str(mult_admissions.shape[0]))\n",
    "print(mult_admissions.head())\n",
    "\n",
    "# Concatenate all subject IDs from patients who survived their first visit\n",
    "relevant_patients = pd.concat([one_admission_survivors, mult_admissions], axis = 0)\n",
    "relevant_patients.columns = relevant_patients.columns.str.strip()\n",
    "relevant_patients = relevant_patients.sort_values('SUBJECT_ID')\n",
    "print(\"Patients who survived their first visit: \" + str(relevant_patients.shape[0]))\n",
    "relevant_patients[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All admissions information for relevant patients\n",
    "all_admissions_for_relevant_patients = pd.merge(relevant_patients, all_admissions_info, how='inner', on='SUBJECT_ID')\n",
    "print(all_admissions_for_relevant_patients.shape[0])\n",
    "all_admissions_for_relevant_patients[4:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for all patients\n",
    "# Only take table info for subjects that are included in our design matrix\n",
    "# Filter via inner join\n",
    "admissions_info = pd.read_sql(\"\"\"SELECT adm.SUBJECT_ID, HADM_ID, ADMITTIME, DISCHTIME\n",
    "                                 FROM admissions adm\n",
    "                                 INNER JOIN patients pat\n",
    "                                 ON adm.SUBJECT_ID = pat.SUBJECT_ID\n",
    "                                 ORDER BY pat.SUBJECT_ID ASC\n",
    "                                 \"\"\", conn)\n",
    "admissions_info['DISCHTIME'] = pd.to_datetime(admissions_info['DISCHTIME'])\n",
    "admissions_info['ADMITTIME'] = pd.to_datetime(admissions_info['ADMITTIME'])\n",
    "\n",
    "all_icustays = pd.read_sql(\"\"\"SELECT icu.SUBJECT_ID, HADM_ID, OUTTIME, LAST_CAREUNIT, LOS\n",
    "                              FROM icustays icu\n",
    "                              INNER JOIN patients pat\n",
    "                              ON icu.SUBJECT_ID = pat.SUBJECT_ID\n",
    "                              ORDER BY pat.SUBJECT_ID ASC\n",
    "                              \"\"\", conn)\n",
    "\n",
    "diagnoses_icd_feats = pd.read_sql(\"\"\"SELECT diag.SUBJECT_ID, HADM_ID, ICD9_CODE\n",
    "                                  FROM diagnoses_icd diag\n",
    "                                  INNER JOIN patients pat\n",
    "                                  ON diag.SUBJECT_ID = pat.SUBJECT_ID\n",
    "                                  ORDER BY pat.SUBJECT_ID ASC\n",
    "                                  \"\"\", conn)\n",
    "\n",
    "# Left joined DRG codes because a lot of DRG severity/mortality data is missing\n",
    "drgcodes_feats = pd.read_sql(\"\"\"SELECT drg.SUBJECT_ID, HADM_ID, DRG_SEVERITY, DRG_MORTALITY \n",
    "                             FROM drgcodes drg\n",
    "                             LEFT JOIN patients pat\n",
    "                             ON drg.SUBJECT_ID = pat.SUBJECT_ID\n",
    "                             ORDER BY pat.SUBJECT_ID ASC\n",
    "                             \"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further process information for admissions and ICU stays\n",
    "# Calculate length of stay for each admission\n",
    "admissions_feats= pd.read_sql(\"\"\"SELECT adm.SUBJECT_ID, HADM_ID, ADMITTIME, DISCHTIME\n",
    "                                 FROM admissions adm\n",
    "                                 INNER JOIN patients pat\n",
    "                                 ON adm.SUBJECT_ID = pat.SUBJECT_ID\n",
    "                                 ORDER BY pat.SUBJECT_ID ASC\n",
    "                                 \"\"\", conn)\n",
    "# 'HOS_LOS' is length of stay in HOSPITAL, in seconds ('TimedeltaProperties' object only\n",
    "# has days, seconds, microseconds as attributes)\n",
    "admissions_feats['HOS_LOS'] = (admissions_info['DISCHTIME'] - admissions_info['ADMITTIME']).dt.seconds\n",
    "# Only get information from FIRST admission\n",
    "admissions_feats.sort_values('DISCHTIME')\n",
    "admissions_feats = admissions_feats.drop_duplicates(subset='SUBJECT_ID', keep='first')\n",
    "admissions_feats = admissions_feats[['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'HOS_LOS']]\n",
    "\n",
    "# Only get information from LAST ICU stay from an admission\n",
    "multiple_icustays = pd.read_sql(\"\"\"SELECT icu.SUBJECT_ID, HADM_ID, LAST_CAREUNIT, LOS\n",
    "                                    FROM icustays icu\n",
    "                                    INNER JOIN patients pat\n",
    "                                    ON icu.SUBJECT_ID = pat.SUBJECT_ID\n",
    "                                    GROUP BY HADM_ID\n",
    "                                    HAVING COUNT(HADM_ID) > 1\n",
    "                                    ORDER BY icu.SUBJECT_ID ASC\n",
    "                                    \"\"\", conn)\n",
    "print(multiple_icustays.shape)\n",
    "multiple_icustays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_icustays[69:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each patient, only keep the LAST ICU stay (if there was one)\n",
    "all_icustays_sorted = all_icustays.sort_values('OUTTIME')\n",
    "icustays_feats = all_icustays_sorted.drop_duplicates(subset=['HADM_ID'], keep='last')\n",
    "icustays_feats = icustays_feats.sort_values('SUBJECT_ID')\n",
    "icustays_feats[67:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "pat_adm_df = pd.read_sql(\"\"\"SELECT pat.SUBJECT_ID, pat.DOB, adm.ADMITTIME\n",
    "                            FROM patients pat\n",
    "                            INNER JOIN admissions adm\n",
    "                            ON pat.SUBJECT_ID = adm.SUBJECT_ID\n",
    "                            ORDER BY pat.SUBJECT_ID ASC\"\"\", conn)\n",
    "\n",
    "admissions_feats['age'] = (pd.to_datetime(pat_adm_df['ADMITTIME']) - pd.to_datetime(pat_adm_df['DOB'])).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(admissions_info.shape)\n",
    "admissions_info[3:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(admissions_feats.shape[0])\n",
    "admissions_feats[4:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_icustays.shape)\n",
    "all_icustays[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diagnoses_icd_feats.shape)\n",
    "diagnoses_icd_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(drgcodes_feats.shape)\n",
    "drgcodes_feats[15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one overall features matrix for ALL patients\n",
    "features_for_all_mat = pd.merge(admissions_feats, icustays_feats[['HADM_ID', 'LAST_CAREUNIT', 'LOS']], how='left', on=['HADM_ID'])\n",
    "print(features_for_all_mat.shape)\n",
    "\n",
    "# Merge feature dataframe with the patient_cols dataframes so we only keep the features\n",
    "# for the RELEVANT patients\n",
    "features_mat = pd.merge(relevant_patients, features_for_all_mat, how='left', on=['SUBJECT_ID'])\n",
    "print(features_mat.shape)\n",
    "features_mat[4:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !!! Need to generate truth labels for ONLY:\n",
    "# - patients who survived their first admission\n",
    "# - the last ICU stay, if there were multiple\n",
    "# - the first admission, if there were multiple\n",
    "\n",
    "# Generate additional columns:\n",
    "# Append truth labels column (Was patient readmitted within 30 days?)\n",
    "# Append 'ICU stay?' column\n",
    "subj_adm = all_admissions_for_relevant_patients[\"SUBJECT_ID\"].value_counts()\n",
    "subj_adm = subj_adm.sort_index()\n",
    "\n",
    "mult_adm_subj = subj_adm.index[subj_adm > 1]\n",
    "\n",
    "# Instantiate to all zeros\n",
    "truth = np.zeros((len(subj_adm)))\n",
    "\n",
    "subj_adm_idx = list(subj_adm.index)\n",
    "\n",
    "for subject in mult_adm_subj:\n",
    "    temp_df = admissions_info[admissions_info[\"SUBJECT_ID\"] == subject]\n",
    "    # Get time between first discharge and second admission\n",
    "    first_disc_time = temp_df[\"DISCHTIME\"].iloc[0]\n",
    "    second_adm_time = temp_df[\"ADMITTIME\"].iloc[1]\n",
    "    days_to_readm = (pd.to_datetime(second_adm_time) - pd.to_datetime(first_disc_time)).days\n",
    "    \n",
    "    # If readmitted within 30 days, set truth to 1\n",
    "    if days_to_readm <= 30:\n",
    "        truth[subj_adm_idx.index(subject)] = 1\n",
    "        \n",
    "truth_df = pd.DataFrame({'SUBJECT_ID': subj_adm_idx, 'READM': np.array(truth, dtype='int')})\n",
    "print(truth_df.head())\n",
    "print(truth_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the truth labels, delete the column ADMITTIME from the features_mat\n",
    "features_mat = features_mat.drop('ADMITTIME', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "design_mat = features_mat.merge(truth_df,how='inner',on=\"SUBJECT_ID\")\n",
    "X = design_mat.iloc[:,2:-1]\n",
    "\n",
    "LCU = design_mat[\"LAST_CAREUNIT\"]\n",
    "le = LabelEncoder() # categorical encoder\n",
    "LCU = le.fit_transform(LCU.astype(str))\n",
    "X['LAST_CAREUNIT'] = LCU\n",
    "X['LOS'] = pd.to_numeric(X['LOS']).fillna(0)\n",
    "\n",
    "# normalize feature values\n",
    "for i in list(X):\n",
    "    X[i] = normalize(X[i][:].values.reshape(-1,1),axis=0)\n",
    "    \n",
    "# make train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, design_mat.iloc[:,-1],test_size = 0.33, random_state = 0)\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(design_mat.shape)\n",
    "print(features_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf=clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "AUC = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
