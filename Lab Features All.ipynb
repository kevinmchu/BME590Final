{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import sqlite3 # library for working with sqlite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GETTING TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection\n",
    "conn = sqlite3.connect(\"./data/labevents_balanced.db\")\n",
    "conn2 = sqlite3.connect(\"./data/lab_events.db\") # keep this\n",
    "\n",
    "# Get dataframe\n",
    "lab_events_df = pd.read_sql(\"\"\"SELECT * FROM labevents\"\"\", conn)\n",
    "lab_items_df = pd.read_sql(\"\"\"SELECT * FROM lab_items\"\"\", conn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric data types\n",
    "lab_events_df[\"SUBJECT_ID\"] = pd.to_numeric(lab_events_df[\"SUBJECT_ID\"])\n",
    "lab_events_df[\"HADM_ID\"] = pd.to_numeric(lab_events_df[\"HADM_ID\"]).astype(int)\n",
    "lab_events_df[\"VALUENUM\"] = pd.to_numeric(lab_events_df[\"VALUENUM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where VALUENUM is nan\n",
    "lab_events_df = lab_events_df.loc[(lab_events_df[\"VALUENUM\"]).notna(), :]\n",
    "\n",
    "# Remove negative values\n",
    "#lab_events_df = lab_events_df.loc[lab_events_df[\"VALUENUM\"] >= 0,:]\n",
    "\n",
    "# Merge with labels for laboratory measurements\n",
    "lab_events_df = lab_events_df.merge(lab_items_df[['ITEMID','LABEL']], left_on='ITEMID', right_on='ITEMID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "lab_events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRUTH LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column 1: SUBJECT_ID\n",
    "# Column 2: TRUTH\n",
    "# Column 3: HADM_ID\n",
    "truth_array = np.loadtxt(\"csv/TRUTH.csv\", delimiter=',', skiprows=1)\n",
    "\n",
    "# Create a dataframe with truth values\n",
    "truth_df = pd.DataFrame(truth_array, columns=['SUBJECT_ID', 'TRUTH', 'HADM_ID'])\n",
    "\n",
    "# Convert to ints\n",
    "truth_df[\"SUBJECT_ID\"] = truth_df[\"SUBJECT_ID\"].astype(int)\n",
    "truth_df[\"TRUTH\"] = truth_df[\"TRUTH\"].astype(int)\n",
    "truth_df[\"HADM_ID\"] = truth_df[\"HADM_ID\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET RELEVANT ADMISSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only interested in lab events corresponding to the relevant admissions\n",
    "relevant_lab_events_df = lab_events_df.merge(truth_df, on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant truth labels\n",
    "hadm_df = pd.DataFrame(lab_events_df[\"HADM_ID\"].unique(), columns={'HADM_ID'})\n",
    "\n",
    "# Get updated truth_df\n",
    "relevant_truth_df = hadm_df.merge(truth_df, how='inner', on='HADM_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the mean of every measurement for every subject\n",
    "avg_df = relevant_lab_events_df.groupby(['HADM_ID', 'LABEL'], as_index = False)['VALUENUM'].median()\n",
    "avg_df = avg_df.rename(index=str, columns={\"VALUENUM\": \"AVG\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_type = np.unique(lab_events_df[\"LABEL\"].get_values())\n",
    "\n",
    "design_mat_df = relevant_truth_df\n",
    "for meas in meas_type:\n",
    "    # Get avg of current measurement\n",
    "    meas_avg_df = avg_df.loc[avg_df[\"LABEL\"] == meas, [\"HADM_ID\", \"AVG\"]]\n",
    "    \n",
    "    # Rename\n",
    "    rename_as = meas + \"_AVG\"\n",
    "    meas_avg_df = meas_avg_df.rename(index=str, columns={\"AVG\": rename_as})\n",
    "    \n",
    "    # Merge\n",
    "    design_mat_df = design_mat_df.merge(meas_avg_df, how='left', on='HADM_ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional columns for missing values\n",
    "#for meas in meas_type:\n",
    "#    # Get current column\n",
    "#    curr_meas = design_mat_df.loc[:, meas + \"_AVG\"]\n",
    "    \n",
    "#    # Add column for missing values\n",
    "#    design_mat_df[meas + \"_AVG_missing\"] = curr_meas.isna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Imputation\n",
    "design_mat_df = design_mat_df.fillna(design_mat_df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y values\n",
    "X = design_mat_df.iloc[:, 3:len(design_mat_df.columns)].get_values()\n",
    "y = design_mat_df.TRUTH.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# make train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#Normalize\n",
    "X_train = normalize(X_train, norm='max', axis=0)\n",
    "X_test = normalize(X_test, norm='max', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "AUC = metrics.auc(fpr, tpr)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
